{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ----- ----- ----- ----- ----- -----\n",
    "# user-defined fields\n",
    "\n",
    "variable = 't2m'   # cfVarName\n",
    "typeOfLevel = 'heightAboveGround' #options: 'heightAboveGround', 'isobaricInhPa', 'surface','sealevel' \n",
    "prototype = 6     # options: 5,6,7,8\n",
    "level = 2\n",
    "\n",
    "# directory to store temporary files\n",
    "cachedir = '/scratch/stan/ufs/cache/'\n",
    "\n",
    "# ----- ----- ----- ----- ----- ----- -----\n",
    "# directories structure of bucket not consistent between prototypes,\n",
    "# address this\n",
    "\n",
    "if prototype == 5:\n",
    "    stradd = ''\n",
    "else:\n",
    "    stradd = 'atmos/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment consists of 141 forecast leads. f000 corresponds to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = np.arange(2011,2019,1).astype('int16')\n",
    "\n",
    "mm = np.arange(1,13)\n",
    "dd = [1, 15]\n",
    "\n",
    "dates = []\n",
    "for year in yy:\n",
    "    for month in mm:\n",
    "        for day in dd:\n",
    "            dates.append(year*10000 + month*100 + day)\n",
    "\n",
    "dates = np.asarray(dates)\n",
    "\n",
    "# remove dates out of range\n",
    "daterange = (dates >= 20110401) & (dates <= 20180315)\n",
    "dates = [date for ii,date in enumerate(dates) if daterange[ii]]\n",
    "\n",
    "# note: 000 corresponds to the analysis\n",
    "steps_num = np.arange(0,846,6)\n",
    "steps = []\n",
    "for step in steps_num: steps.append('{:03d}'.format(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coordinates info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyyymmdd=str(dates[0])\n",
    "\n",
    "of = fsspec.open_local(\"filecache::https://noaa-ufs-prototypes-pds.s3.amazonaws.com/Prototype\"+str(prototype)+\n",
    "                       \"/\"+yyyymmdd+\"/pgrb2/gfs.\"+yyyymmdd+\"/00/\"+stradd+\"gfs.t00z.pgrb2.0p25.f048\",\n",
    "                           s3={'anon': True}, filecache={'cache_storage':cachedir})     \n",
    "\n",
    "ds_sf0 = xr.open_dataset(of, engine='cfgrib',\n",
    "                         backend_kwargs={'filter_by_keys':{'cfVarName':variable,'typeOfLevel':typeOfLevel,'level':level},\n",
    "                        'indexpath':cachedir+'gfs.{short_hash}.idx'})\n",
    "\n",
    "latitude = ds_sf0.latitude\n",
    "longitude = ds_sf0.longitude\n",
    "\n",
    "# Clear cache\n",
    "os.system('rm ' + cachedir + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,yyyymmdd in enumerate(dates):\n",
    "    \n",
    "    # Construct time variable\n",
    "    strt_time=datetime.datetime(int(str(yyyymmdd)[0:4]),\n",
    "                                int(str(yyyymmdd)[4:6]),\n",
    "                                int(str(yyyymmdd)[6:8]),0,0,0)\n",
    "    time=[strt_time+datetime.timedelta(hours=int(steps[i])) for i in range(len(steps)-1)]\n",
    " \n",
    "    # Define xarray to store all forecast leads. This case is for 2 metre temperature (t2m)\n",
    "    t2m = xr.DataArray(\n",
    "        np.ndarray([len(steps)-1,len(latitude),len(longitude)]),\n",
    "        coords={'latitude':latitude,'longitude':longitude,'time':time},\n",
    "        dims=['time','latitude','longitude']\n",
    "        )\n",
    "    t2m.attrs['units'] = 'K'\n",
    "    t2m.attrs['name'] = '2 metre temperature'\n",
    "\n",
    "    # Read all forecast leads and store them into the xarray defined at previous step. \n",
    "    # Forecast lead f000 will be neglected. Note: Precipitation is defined as 6h accumulation, thus f000 is undefined.\n",
    "    \n",
    "    for i,istep in enumerate(steps[1:]):\n",
    "    \n",
    "        of = fsspec.open_local(\"filecache::https://noaa-ufs-prototypes-pds.s3.amazonaws.com/Prototype\"+str(prototype)+\n",
    "                            \"/\"+str(yyyymmdd)+\"/pgrb2/gfs.\"+str(yyyymmdd)+\"/00/\"+stradd+\"gfs.t00z.pgrb2.0p25.f\"+istep,\n",
    "                           s3={'anon': True}, filecache={'cache_storage':cachedir})     \n",
    "        ds_iso = xr.open_dataset(of, engine='cfgrib',\n",
    "                     backend_kwargs={'filter_by_keys':{'cfVarName':variable,'typeOfLevel':typeOfLevel,'level':level},\n",
    "                                    'indexpath': cachedir+'gfs.t00z.pgrb2.0p25.f'+istep+'.idx'})\n",
    "        t2m[i,:,:] = ds_iso.t2m.load()\n",
    "        \n",
    "        del ds_iso\n",
    "        gc.collect()\n",
    "        \n",
    "    # Clear cache\n",
    "    os.system('rm ' + cachedir + '*')\n",
    "    \n",
    "    # Compute daily means \n",
    "    t2m = t2m.resample(time='D').mean()\n",
    "    t2m.attrs['units'] = 'K'\n",
    "    t2m.attrs['name'] = '2 metre temperature'\n",
    "    time_daily_mean = t2m['time']\n",
    "    \n",
    "    # Write out in netcdf format using single precision. \n",
    "    # If multiple varaibles are to be writen out, repeat this step for the other variables \n",
    "    # and then concatenate then over time as shown in the comment line, and modify the encoding line accordingly.\n",
    "    \n",
    "    ds_out = xr.DataArray(\n",
    "        t2m.rename('t2m'),\n",
    "        coords={'latitude':latitude,'longitude':longitude,'time':time_daily_mean},\n",
    "        dims=['time','latitude','longitude']\n",
    "        )\n",
    "\n",
    "    #ds_out = xr.concat([ds1_out['var1'], ds2_out['var2']], dim=\"time\")\n",
    "\n",
    "    encoding = {'latitude': {'dtype':'float32','_FillValue': None},\n",
    "                'longitude': {'dtype':'float32','_FillValue': None},\n",
    "                'time': {'dtype':'int32'},\n",
    "                't2m':{'dtype':'float32'}\n",
    "                }\n",
    "\n",
    "    ds_out.to_netcdf(\"/project/navgem/data/ufs6/mean/t2m_\"+str(yyyymmdd)+\".nc\", encoding=encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
