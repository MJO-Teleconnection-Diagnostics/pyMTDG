{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each experiment consists of 141 forecast leads. f000 corresponds to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['000','006','012','018','024','030','036','042',\n",
    "         '048','054','060','066','072','078','084','090',\n",
    "         '096','102','108','114','120','126','132','138',\n",
    "         '144','150','156','162','168','174','180','186',\n",
    "         '192','198','204','210','216','222','228','234',\n",
    "         '240','246','252','258','264','270','276','282',\n",
    "         '288','294','300','306','312','318','324','330',\n",
    "         '336','342','348','354','360','366','372','378',\n",
    "         '384','390','396','402','408','414','420','426',\n",
    "         '432','438','444','450','456','462','468','474',\n",
    "         '480','486','492','498','504','510','516','522',\n",
    "         '528','534','540','546','552','558','564','570',\n",
    "         '576','582','588','594','600','606','612','618',\n",
    "         '624','630','636','642','648','654','660','666',\n",
    "         '672','678','684','690','696','702','708','714',\n",
    "         '720','726','732','738','744','750','756','762',\n",
    "         '768','774','780','786','792','798','804','810',\n",
    "         '816','822','828','834','840']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time stamp of the forecast. yyyymm01 coresponds to 1st of the month IC, yyyymm15 corresponds to 15th of the month IC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyymmdd = '20140601'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coordinates info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = fsspec.open_local(\"filecache::https://noaa-ufs-prototypes-pds.s3.amazonaws.com/Prototype7/\"+yyyymmdd+\"/pgrb2/gfs.\"+yyyymmdd+\"/00/atmos/gfs.t00z.pgrb2.0p25.f006\",\n",
    "                           s3={'anon': True}, filecache={'cache_storage':'/scratch/stan/ufs/'})     \n",
    "\n",
    "ds_sf0 = xr.open_dataset(of, engine='cfgrib',\n",
    "                         backend_kwargs={'filter_by_keys':{'cfVarName': 'gh','typeOfLevel':'isobaricInhPa'}})\n",
    "\n",
    "latitude = ds_sf0.latitude\n",
    "longitude = ds_sf0.longitude\n",
    "strt_time=datetime.datetime(int(yyyymmdd[0:4]),int(yyyymmdd[4:6]),int(yyyymmdd[6:8]),0,0,0)\n",
    "time=[strt_time+datetime.timedelta(hours=int(steps[i])) for i in range(len(steps)-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define xarray to store all forecast leads. This case is for 500hPa geopotential height (gh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh500 = xr.DataArray(\n",
    "    np.ndarray([len(steps)-1,len(latitude),len(longitude)]),\n",
    "    coords={'latitude':latitude,'longitude':longitude,'time':time},\n",
    "    dims=['time','latitude','longitude']\n",
    ")\n",
    "gh500.attrs['units'] = 'gpm'\n",
    "gh500.attrs['name'] = '500hPa geopotential height'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all forecast leads and store them into the xarray defined at previous step. Forecast lead f000 will be neglected. Note: Precipitation is defiined as 6h accoumulation, thus f000 is undefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for istep in steps[1:]:\n",
    "    \n",
    "    of = fsspec.open_local(\"filecache::https://noaa-ufs-prototypes-pds.s3.amazonaws.com/Prototype7/\"+yyyymmdd+\"/pgrb2/gfs.\"+yyyymmdd+\"/00/atmos/gfs.t00z.pgrb2.0p25.f\"+istep,\n",
    "                           s3={'anon': True}, filecache={'cache_storage':'/scratch/stan/ufs/'})     \n",
    "    ds_iso = xr.open_dataset(of, engine='cfgrib',\n",
    "                     backend_kwargs={'filter_by_keys':{'typeOfLevel':'isobaricInhPa','name':'Geopotential Height','level':500}})\n",
    "    gh500[i,:,:] = ds_iso.gh\n",
    "    \n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute daily means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z500 = gh500.resample(time='D').mean(dim='time')\n",
    "z500.attrs['units'] = 'gpm'\n",
    "z500.attrs['name'] = '500hPa geopotential height'\n",
    "time_daily_mean = z500['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out in netcdf format using single precision. If multiple varaibles are to be writen out, repeat this step for the other variables and then concatenate then over time as shown in the comment line, and modify the encoding line accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = xr.DataArray(\n",
    "    z500.rename('z500'),\n",
    "    coords={'latitude':latitude,'longitude':longitude,'time':time_daily_mean},\n",
    "    dims=['time','latitude','longitude']\n",
    ")\n",
    "\n",
    "#ds_out = xr.concat([ds1_out['var1'], ds2_out['var2']], dim=\"time\")\n",
    "\n",
    "encoding = {'latitude': {'dtype':'float32','_FillValue': None},\n",
    "            'longitude': {'dtype':'float32','_FillValue': None},\n",
    "            'time': {'dtype':'int32'},\n",
    "            'z500':{'dtype':'float32'}\n",
    "            }\n",
    "\n",
    "ds_out.to_netcdf(\"/scratch/stan/ufs/z500_\"+yyyymmdd+\".nc\", encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The code creates some files in the directory specified in \"filecache\". Delete these files after you process the \"yyyymmdd\" forecast case. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
